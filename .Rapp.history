38-14
24*3
40*50
50/2000
448-299
448-298
298+133
298-149
299-147
296-149
448-298
1.875/2
1/8
2-0.125
?pwr.t.test
??pwr.t.test
pwr.t.test(d=0.125,sig.level=0.5,power=0.8,type="paired",alternative="two.sided")
library(pwr)
pwr.t.test(d=0.125,sig.level=0.5,power=0.8,type="paired",alternative="two.sided")
pwr.t.test(d=0.125,sig.level=0.05,power=0.8,type="paired",alternative="two.sided")
pwr.chisq.test(w = 0.125, df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = 0.125, df = 1, sig.level = 0.05, power = 0.9)
250*.12
chi.sq()
?chisq.test
matrix(c(0,250,30,250),nrow=2,ncol=2)
matrix(c(0,250,30,250),nrow=2,ncol=2,byrow=T)
matrix(c(0,250,30,220),nrow=2,ncol=2,byrow=T)
demo<-matrix(c(0,250,30,220),nrow=2,ncol=2,byrow=T)
chisq.test(demo)
demo<-matrix(c(0,25,3,22),nrow=2,ncol=2,byrow=T)
chisq.test(demo)
demo<-matrix(c(0,50,6,44),nrow=2,ncol=2,byrow=T)
chisq.test(demo)
sum(demo)
demo<-matrix(c(1,49,6,44),nrow=2,ncol=2,byrow=T)
chisq.test(demo)
demo<-matrix(c(0,100,12,88),nrow=2,ncol=2,byrow=T)
chisq.test(demo)
demo<-matrix(c(1,99,12,88),nrow=2,ncol=2,byrow=T)
chisq.test(demo)
demo<-matrix(c(2,98,12,88),nrow=2,ncol=2,byrow=T)
chisq.test(demo)
demo<-matrix(c(3,97,12,88),nrow=2,ncol=2,byrow=T)
chisq.test(demo)
ES.h
?ES.h
pwr.chisq.test(w = ES.h (0.2,0.1875), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.h(p1=0.2,p2=0.1875), df = 1, sig.level = 0.05, power = 0.8)
ES.h(p1=0.2,p2=0.1875)
?ES.h
h<-ES.h(0.5,0.4)
h
pwr.chisq.test(w = ES.h(p1=0.2, p2=0.1), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.h(p1=0.2, p2=0.15), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.h(p1=0.2, p2=0.1875), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.h(p1=0.8, p2=0.7875), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.h(p1=0.12, p2=0), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.h(p1=0.2, p2=0.1), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
null<-c(20,80,20,80)#
alt<-c(19,81,20,80)#
#
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
1-0.1875
null<-c(0.2,0.8,0.2,0.8)#
alt<-c(0.1875,0.8125,0.2,0.8)#
#
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
?ES.w1
alt<-c(0.1,0.9,0.2,0.8)
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
1/8
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
null<-c(0.2,0.8,0.2,0.8)#
alt<-c(0.1875,0.8125,0.2,0.8)#
#
# alt<-c(0.1,0.9,0.2,0.8)#
#
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.6)
100-12
null<-c(0.12,0.88,0.12,0.88)#
alt<-c(0,100,0.12,0.88)#
#
pwr.chisq.test(w = ES.h(p1=0.2, p2=0.1875), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
null<-c(0.12,0.88,0.12,0.88)#
alt<-c(0,1,0.12,0.88)#
#
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
?ES.w1
1-0.01875
null<-c(0.98,0.98,0.02,0.02)#
alt<-c(0.98,0.98125,0.02,0.01875)
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
null<-c(0.98,0.02,0.98,0.02)#
alt<-c(0.98,0.02,0.98125,0.01875)#
# alt<-c(0.1,0.9,0.2,0.8)#
#
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
alt<-c(0.98,0.99,0.02,0.01)
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
null<-c(0.98,0.98,0.02,0.02)
alt<-c(0.98,0.99,0.02,0.01)
pwr.chisq.test(w = ES.w1(null,alt), df = 1, sig.level = 0.05, power = 0.8)
ES.w1(null,alt1)
alt1<-c(0.98,0.98125,0.02,0.01875)#
alt2<-c(0.98,0.99,0.02,0.01)
ES.w1(null,alt1)
ES.w1(null,alt2)
2/12
10/12
h<-ES.h(0.5,0.4)
h
ES.h(0.02,0.01875)
alt1<-c(0.98,0.98125,0.02,0.01875)
ES.w1(null,alt1)
pwr.chisq.test(w = ES.h(p1=0.2, p2=0.1875), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.h(p1=0.02, p2=0.01875), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.w1(null,alt1), df = 1, sig.level = 0.05, power = 0.8)
?ES.w1
?pwr.chisq.test
citation (pwr)
citation(pwr)
citation("pwr")
citation()
?ES.w1
null<-c(0.98,0.98,0.02,0.02)#
alt1<-c(0.98,0.98125,0.02,0.01875)#
alt2<-c(0.98,0.99,0.02,0.01)
ES.w1(null,alt1)
pwr.chisq.test(w = ES.w1(null,alt1), df = 1, sig.level = 0.05, power = 0.6)
pwr.chisq.test(w = ES.w1(null,alt1), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.w1(null,alt1), df = 1, sig.level = 0.05, power = 0.6)
alt2<-c(0.98,0.99,0.02,0.01)#
#
pwr.chisq.test(w = ES.w1(null,alt2), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.w1(null,alt2), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.w1(null,alt2), df = 1, sig.level = 0.05, power = 0.6)
pwr.tst<-pwr.chisq.test(w = ES.w1(null,alt2), df = 1, sig.level = 0.05, power = pwrs[i])
pwrs<-seq(0.5,1,0.1)
i=1
pwr.tst<-pwr.chisq.test(w = ES.w1(null,alt2), df = 1, sig.level = 0.05, power = pwrs[i])
pwr.tst
names(pwr.test)
names(pwr.tst)
pwrs<-seq(0.5,1,0.1)#
ns<-c()#
for (i in 1:length(pwrs)){#
	pwr.tst<-pwr.chisq.test(w = ES.w1(null,alt2), df = 1, sig.level = 0.05, power = pwrs[i])#
	ns[i]<-pwr.tst$N#
}
plot(pwrs,ns)
pwrs<-seq(0.5,0.9,0.1)#
ns<-c()#
for (i in 1:length(pwrs)){#
	pwr.tst<-pwr.chisq.test(w = ES.w1(null,alt2), df = 1, sig.level = 0.05, power = pwrs[i])#
	ns[i]<-pwr.tst$N#
}#
#
plot(pwrs,ns)
plot(pwrs,ns,ylab="N",xlab="Power")
plot(pwrs,ns,ylab="N",xlab="Power",pch=16)
plot(pwrs,ns,ylab="N",xlab="Power",pch=16,las=1)
pwrs<-seq(0.5,0.9,0.1)#
ns_h1<-c()#
for (i in 1:length(pwrs)){#
	pwr.tst<-pwr.chisq.test(w = ES.w1(null,alt1), df = 1, sig.level = 0.05, power = pwrs[i])#
	ns[i]<-pwr.tst$N#
}
plot(pwrs,ns_h1,ylab="N",xlab="Power",pch=16,las=1)#
points(pwrs,ns_h2)
pwrs<-seq(0.5,0.9,0.1)#
ns_h2<-c()#
for (i in 1:length(pwrs)){#
	pwr.tst<-pwr.chisq.test(w = ES.w1(null,alt2), df = 1, sig.level = 0.05, power = pwrs[i])#
	ns[i]<-pwr.tst$N#
}#
pwrs<-seq(0.5,0.9,0.1)#
ns_h1<-c()#
for (i in 1:length(pwrs)){#
	pwr.tst<-pwr.chisq.test(w = ES.w1(null,alt1), df = 1, sig.level = 0.05, power = pwrs[i])#
	ns[i]<-pwr.tst$N#
}#
plot(pwrs,ns_h1,ylab="N",xlab="Power",pch=16,las=1)#
points(pwrs,ns_h2)
plot(pwrs,ns_h1,ylab="N",xlab="Power",pch=16,las=1)
pwrs<-seq(0.5,0.9,0.1)#
ns_h2<-c()#
for (i in 1:length(pwrs)){#
	pwr.tst<-pwr.chisq.test(w = ES.w1(null,alt2), df = 1, sig.level = 0.05, power = pwrs[i])#
	ns_h2[i]<-pwr.tst$N#
}#
pwrs<-seq(0.5,0.9,0.1)#
ns_h1<-c()#
for (i in 1:length(pwrs)){#
	pwr.tst<-pwr.chisq.test(w = ES.w1(null,alt1), df = 1, sig.level = 0.05, power = pwrs[i])#
	ns_h1[i]<-pwr.tst$N#
}#
plot(pwrs,ns_h1,ylab="N",xlab="Power",pch=16,las=1)#
points(pwrs,ns_h2)
ns_h2
plot(pwrs,ns_h1,ylab="N",xlab="Power",pch=16,las=1,ylimc=c(0,130000))#
points(pwrs,ns_h2)
plot(pwrs,ns_h1,ylab="N",xlab="Power",pch=16,las=1,ylim=c(0,130000))#
points(pwrs,ns_h2)
plot(pwrs,ns_h2,ylab="N",xlab="Power",pch=16,las=1)
plot(pwrs,ns_h1,ylab="N",xlab="Power",pch=16,las=1,ylim=c(0,130000))
plot(pwrs,ns_h2,ylab="N",xlab="Power",pch=16,las=1)
alt3<-c(0.98,1,0.02,0)
pwr.chisq.test(w = ES.w1(null,alt3), df = 1, sig.level = 0.05, power = 0.8)
pwr.chisq.test(w = ES.w1(null,alt3), df = 1, sig.level = 0.05, power = 0.6)
alt3<-c(0.98,1,0.02,0)#
#
pwr.chisq.test(w = ES.w1(null,alt3), df = 1, sig.level = 0.05, power = 0.8)
pwrs<-seq(0.5,0.9,0.1)#
ns_h3<-c()#
for (i in 1:length(pwrs)){#
	pwr.tst<-pwr.chisq.test(w = ES.w1(null,alt3), df = 1, sig.level = 0.05, power = pwrs[i])#
	ns_h3[i]<-pwr.tst$N#
}
plot(pwrs,ns_h3,ylab="N",xlab="Power",pch=16,las=1,ylim=c(0,130000))
plot(pwrs,ns_h3,ylab="N",xlab="Power",pch=16,las=1)
sum(alt3)
sum(alt2)
sum(alt1)
sum(null)
alt3<-c(0.98,1,0.02,0)
pwr.chisq.test(w = ES.w1(null,alt3), df = 1, sig.level = 0.05, power = 0.8)
ES.w1(null,alt3)
ES.w1(null,alt2)
pwr.chisq.test(w = ES.w1(null,alt3), df = 1, sig.level = 0.05, power = 0.8)
# LIBRARIES#
#
library(rioja)#
library(princurve)#
library(bcp)#
#
# FUNCTIONS#
source('~/Desktop/Research_Git/PaleoVegChange/PaleoVegChange_functions.R', chdir = TRUE)#
#
# NEOTOMA DOWNLOAD OBJECT#
load('~/Desktop/Research_Git/PaleoVegChange/pol_dlx_2020-12-01.Rdata')
# sl.id<-which(names(pol_dlx) == "17396") # steel lake#
# sl.id<-which(names(pol_dlx) == "2576")	# slough creek ##
# sl.id<-which(names(pol_dlx) == "14803") # burnt knob lake ##
# sl.id<-which(names(pol_dlx) == "14933") # nelson lake#
# sl.id<-which(names(pol_dlx) == "14997") # round pond #
# sl.id<-which(names(pol_dlx) == "203") # anderson pond ####
# sl.id<-which(names(pol_dlx) == "15088") # anderson pond ####
# sl.id<-which(names(pol_dlx) == "20397") # south rhody ####
#
sl.id<-which(names(pol_dlx) == "971") # Gould pond#
#
sl.pol.cnts<-pol_dlx[[sl.id]]$counts#
#
sl.pol.pcts<-clean_pollen(pol_dlx[[sl.id]],type="pct",eco.grou=c("TRSH","UPHE"))#
#
# sl.pol.pcts<-sl.pol.cnts/rowSums(sl.pol.cnts)#
# sort(colSums(sl.pol.pcts),decreasing=T)#
#
pol.rank<-order(colSums(sl.pol.pcts),decreasing=T)#
pol.sub<-sl.pol.pcts[,pol.rank[1:12]]#
#
# Run principal curve#
pc<-principal_curve(sqrt(sl.pol.pcts))#
#
# plot pollen diagram#
#
temp<-cbind(pol.sub*100,pc$lambda)#
colnames(temp)[13]<-"Principal Curve"#
#
YLIM<-c(2200,750)#
dev.new(width=10,height=6)#
par(oma=c(1,1,2,3))#
# strat.plot(pol.sub,yvar=pol_dlx[[sl.id]]$sample.meta$depth,y.rev=T,ylim=c(0,1200))#
#
strat.plot(temp,yvar=pol_dlx[[sl.id]]$sample.meta$depth,y.rev=T,ylim=rev(YLIM),plot.poly=T,plot.line=T,plot.bar=F,col.poly=c(rep("gray40",12),rgb(0,0,0,0)),col.poly.line=rgb(0,0,0,0),cex.xlabel=0.75,srt.xlabel=45,cex.axis=0.65,tcl=-0.25)#
#
mtext("Depth (cm)",2,3.5,outer=F)#
#
# # plot Principle curve#
# plot(pc$lambda,pol_dlx[[sl.id]]$sample.meta$depth,type="l",lwd=0.5,ylim=YLIM,ylab="Depth (cm)",xlab="Principal Curve Lambda")#
# points(pc$lambda,pol_dlx[[sl.id]]$sample.meta$depth,pch=16)#
# plot BCP#
bcp.out<-bcp(pc$lambda,mcmc=10000,burnin=1000,w0=0.2,p0=0.05) # run bcp#
bcp.out.summary<-summary(bcp.out)#
dev.new(width=4.5,height=6)#
par(mfrow=c(1,2),mar=c(4,1,1,0),oma=c(1,4,1,1))#
#
plot(bcp.out$data[,2],pol_dlx[[sl.id]]$sample.meta$depth,ylim=YLIM,pch=16,cex=0.5,ylab="Depth (cm)",xlab="Posterior Means",las=1,col="blue")#
lines(bcp.out.summary[,2],pol_dlx[[sl.id]]$sample.meta$depth,col="blue")#
mtext("Depth (cm)",2,3)#
abline(h=pol_dlx[[sl.id]]$sample.meta$depth[which(bcp.out$posterior.prob>0.5)],lty=3,col="red")#
#
plot(bcp.out$posterior.prob,pol_dlx[[sl.id]]$sample.meta$depth,type="l",lwd=0.5,ylim=YLIM,ylab=" ",yaxt="n",xlab="Posterior Probability")#
# abline(v=0.5,lty=3)
citation("princuve")
citation("princurve")
3854+2036
ddt<-read.csv("~/Desktop/Research_Git/JRBP_Cores/pesticides/JRBP2018-VC01A_DDT.csv")
am<-read.csv("~/Desktop/Research_Git/JRBP_Cores/CT Ti Age model/JRBP2018-VC01A_AgeModel_2022-06-17.csv")
# LOAD DATA#
ddt<-read.csv("~/Desktop/Research_Git/JRBP_Cores/pesticides/JRBP2018-VC01A_DDT.csv")#
#
am<-read.csv("~/Desktop/Research_Git/JRBP_Cores/CT Ti Age model/JRBP2018-VC01A_AgeModel_2022-06-17.csv")
head(ddt)
head(am)
samp_top_interp_upper<-approx(am$Depth..cm.,am$Upper.Age.Est,xout=ddt$Upper.Depth)#
samp_top_interp_median<-approx(am$Depth..cm.,am$Age.Est,xout=ddt$Upper.Depth)#
samp_top_interp_lower<-approx(am$Depth..cm.,am$Lower.Age.Est,xout=ddt$Upper.Depth)#
#
samp_base_interp_upper<-approx(am$Depth..cm.,am$Upper.Age.Est,xout=ddt$Lower.Depth)#
samp_base_interp_median<-approx(am$Depth..cm.,am$Age.Est,xout=ddt$Lower.Depth)#
samp_base_interp_lower<-approx(am$Depth..cm.,am$Lower.Age.Est,xout=ddt$Lower.Depth)
cbind(ddt$Upper.Depth,samp_top_interp_lower$y,samp_top_interp_median$y,samp_top_interp_upper$y)
samp.top.am<-cbind(ddt$Upper.Depth,samp_top_interp_lower$y,samp_top_interp_median$y,samp_top_interp_upper$y)#
#
samp.base.am<-cbind(ddt$Upper.Depth,samp_base_interp_lower$y,samp_base_interp_median$y,samp_base_interp_upper$y)
samp.mean.age<-(samp.top.am[,3]+samp.base.am[,3])/2
samp.mean.age
samp.mean.depth<-c(ddt$Lower.Depth+ddt$Upper.Depth)/2
samp.mean.depth
am.mean<-cbind(samp.mean.depth,samp.mean.age)
am.mean
am.mean[1,2]<-2019
am.mean
head(ddt)
plot(am.mean[,2],ddt$Total.DDx)
plot(am.mean[,2],ddt$Total.DDx,type="l")
age.range<-cbind(ddt$Upper.Depth,ddt$Lower.Depth,samp.upper.est,samp.lower.est)
# find age upper/lower for each sample#
samp.upper.est<-samp.top.am[,4]#
samp.lower.est<-samp.base.am[,2]#
#
age.range<-cbind(ddt$Upper.Depth,ddt$Lower.Depth,samp.upper.est,samp.lower.est)
head(age.range)
colnames(age.range)<-c("upper.depth","lower.depth","upper.age.est","lower.age.est")
head(age.range)
segments(x0=ddt$Total.DDx,x1=ddt$Total.DDx,y0=samp.upper.est,y1=samp.lower.est)
plot(ddt$Total.DDx,am.mean[,2],type="l")#
segments(x0=ddt$Total.DDx,x1=ddt$Total.DDx,y0=samp.upper.est,y1=samp.lower.est)
plot(ddt$Total.DDx,am.mean[,2],type="l",lwd=0.5)#
segments(x0=ddt$Total.DDx,x1=ddt$Total.DDx,y0=samp.upper.est,y1=samp.lower.est)
plot(ddt$Total.DDx,am.mean[,2],type="l",lwd=0.5,main="DDx")
segments(x0=ddt$Total.DDx,x1=ddt$Total.DDx,y0=samp.upper.est,y1=samp.lower.est)
head(ddt)
plot(ddt$DDD,am.mean[,2],type="l",lwd=0.5,main="Total DDD")#
segments(x0=ddt$DDD,x1=ddt$DDD,y0=samp.upper.est,y1=samp.lower.est)
# plot DDT data#
plot(ddt$Total.DDx,am.mean[,2],type="l",lwd=0.5,main="Total DDx")#
segments(x0=ddt$Total.DDx,x1=ddt$Total.DDx,y0=samp.upper.est,y1=samp.lower.est)
plot(ddt$DDE,am.mean[,2],type="l",lwd=0.5,main="Total DDE")#
segments(x0=ddt$DDE,x1=ddt$DDE,y0=samp.upper.est,y1=samp.lower.est)
plot(ddt$DDT,am.mean[,2],type="l",lwd=0.5,main="Total DDT")#
segments(x0=ddt$DDT,x1=ddt$DDT,y0=samp.upper.est,y1=samp.lower.est)
sum(ddt$X24DDT,ddt$X44DDT)
rowSums(ddt$X24DDT,ddt$X44DDT
)
plot(rowSums(ddt[,c("X24DDT","X$4DDT")]),am.mean[,2],type="l",lwd=0.5,main="Total DDT")
plot(rowSums(ddt[,c("X24DDT","X44DDT")]),am.mean[,2],type="l",lwd=0.5,main="Total DDT")
segments(x0=rowSums(ddt[,c("X24DDT","X44DDT")]),x1=rowSums(ddt[,c("X24DDT","X44DDT")]),y0=samp.upper.est,y1=samp.lower.est)
plot(ddt$Total.DDx,am.mean[,2],type="l",lwd=0.5,main="Total DDx")
polygon(x=c(rep(0,length(ddt$Total.DDx)),rev(ddt$Total.DDx)),y=c(am.mean[,2],rev(am.mean[,2])),col="blue")
polygon(x=c(rep(0,length(ddt$Total.DDx)),rev(ddt$Total.DDx)),y=c(am.mean[,2],rev(am.mean[,2])),col="red")
cbind(ddt$DDE,ddt$DDD)
plot(rowSums(ddt[,c("X24DDT","X44DDT")]),am.mean[,2],type="l",lwd=0.5,main="Total DDT")#
segments(x0=rowSums(ddt[,c("X24DDT","X44DDT")]),x1=rowSums(ddt[,c("X24DDT","X44DDT")]),y0=samp.upper.est,y1=samp.lower.est)
plot(ddt$Total.DDx,am.mean[,2],type="l",lwd=0.5,main="Total DDx")#
#
polygon(x=c(rep(0,length(ddt$Total.DDx)),rev(ddt$Total.DDx)),y=c(am.mean[,2],rev(am.mean[,2])),col="red")
polygon(x=c(rep(0,length(ddt$Total.DDx)),rev(rowSums(ddt[,c("DDE","DDD")]))),y=c(am.mean[,2],rev(am.mean[,2])),col="orange")
polygon(x=c(rep(0,length(ddt$Total.DDx)),rev(ddt$Total.DDx)),y=c(am.mean[,2],rev(am.mean[,2])),col="red")
polygon(x=c(rep(0,length(ddt$Total.DDx)),rev(rowSums(ddt[,c("DDE","DDD")]))),y=c(am.mean[,2],rev(am.mean[,2])),col="orange")
polygon(x=c(rep(0,length(ddt$Total.DDx)),rev(rowSums(ddt[,c("DDD")]))),y=c(am.mean[,2],rev(am.mean[,2])),col="yellow")
polygon(x=c(rep(0,length(ddt$Total.DDx)),rev(ddt[,c("DDD")])),y=c(am.mean[,2],rev(am.mean[,2])),col="yellow")
age.range
max.timespan<-age.range[,3]-age.range[,4]
samp.top.am
timespan<-samp.top.am[,3]-samp.top.am[,4]
timespan
timespan<-samp.top.am[,3]-samp.base.am[,3]
timespan
plot(timespan,ddt$Total.DDx)
plot(timespan,ddt$DDD)
plot(timespan,ddt$DDE)
i=1
pol_ds<-pol_dlx[[i]]#
	am_posteriors<-get_am_posteriors(pol_ds)#
	am_posteriors<-am_posteriors[complete.cases(am_posteriors),]#
	prep.pol<-prep_pollen(pol_ds,eco.group,type="pct")
# LIBRARIES ########################################
library(rgdal)#
library(geosphere)#
#
# LOAD DATA ########################################
# NEOTOMA R OBJECT___#
load('pol_dlx_2020-12-01.Rdata')#
#
# LOAD AGE MODELS___#
# Bayesian age models used here are from Wang et al. (2019) Bayesian ages for pollen records since the last glaciation. Sci Data 6, 176#
# code to generate these age models is available at https://github.com/yuewangpaleo/BaconAgeNeotoma#
# Age models here are provided with permission from Y. Wang#
#
path<-"Wang-et-al-Cores" # file path for age model data
source('PaleoVegChange_functions.R', chdir = TRUE)
getwd()
setwd("~/Desktop/Research_Git/PaleoVegChange")
# LIBRARIES ########################################
library(rgdal)#
library(geosphere)#
#
# LOAD DATA ########################################
# NEOTOMA R OBJECT___#
load('pol_dlx_2020-12-01.Rdata')#
#
# LOAD AGE MODELS___#
# Bayesian age models used here are from Wang et al. (2019) Bayesian ages for pollen records since the last glaciation. Sci Data 6, 176#
# code to generate these age models is available at https://github.com/yuewangpaleo/BaconAgeNeotoma#
# Age models here are provided with permission from Y. Wang#
#
path<-"Wang-et-al-Cores" # file path for age model data
source('PaleoVegChange_functions.R', chdir = TRUE)
pol_ds<-pol_dlx[[i]]#
	am_posteriors<-get_am_posteriors(pol_ds)#
	am_posteriors<-am_posteriors[complete.cases(am_posteriors),]
path<-"~/Desktop/Yue Cores/Cores_all"
pol_ds<-pol_dlx[[i]]#
	am_posteriors<-get_am_posteriors(pol_ds)#
	am_posteriors<-am_posteriors[complete.cases(am_posteriors),]
am_posteriors[,1:10]
file.name<-dir(handle.path,pattern="ages.txt") # use handle to import bacon iterations
pol_ds<-pol_dlx[[i]]#
	handlej<-pol_ds$dataset$dataset.meta$collection.handle # get site handle#
	handle.path<-paste(path,"/",handlej,sep="") #
	file.name<-dir(handle.path,pattern="ages.txt") # use handle to import bacon iterations#
	file.path<-paste(handle.path,"/",file.name,sep="")
file.path
read.table(file.path)
am_iters<-read.table(file.path,header=T)
am_iters
range(am$median)
meta.out<-matrix(NA,nrow=nrow(site.meta),ncol=4)#
for (i in 1:nrow(site.meta)){#
	site.i<-pol_dlx[[site.meta$dataset.id[i]]]#
	n.samp<-nrow(site.i$sample.meta) # number of samples#
	# age.range<-round(range(site.i$sample.meta$age)) # time span#
	n.terrestrial<-ncol(clean_pollen(site.i,type="pct",eco.group=c("TRSH","UPHE"))) # number of terrestrial pollen types#
	pol_ds<-pol_dlx[[i]]#
	handlej<-pol_ds$dataset$dataset.meta$collection.handle # get site handle#
	handle.path<-paste(path,"/",handlej,sep="") #
	file.name<-dir(handle.path,pattern="ages.txt") # use handle to import bacon iterations#
	file.path<-paste(handle.path,"/",file.name,sep="")#
	am<-read.table(file.path,header=T)#
	age.range<-range(am$median)#
	meta.out[i,]<-c(n.samp,n.terrestrial,age.range)#
}
# LOAD ECOREGIONS SHAPEFILE__#
# Download the Level I Ecoregions of North America Shapefile available at:#
# https://www.epa.gov/eco-research/ecoregions-north-america#
ecoregions<-readOGR("na_cec_eco_l1/NA_CEC_Eco_Level1.shp") # replace with appropriate file path#
#
# FUNCTIONS ######################
# LOAD FUNCTIONS__#
source('PaleoVegChange_functions.R', chdir = TRUE)#
#
# ADDITIONAL FUNCTIONS FOR DEFIINING REGIONS___#
extract.coords<-function(pol_dl_obj){#
	coords<-matrix(NA,nc=3,nr=length(pol_dl_obj))#
	for (i in 1:length(pol_dl_obj)){#
		coords[i,]<-c(pol_dl_obj[[i]]$dataset$dataset.meta$dataset.id,pol_dl_obj[[i]]$dataset$site.data$long,pol_dl_obj[[i]]$dataset$site.data$lat)	#
	}#
	return(coords)#
}#
#
# point.in.region________________________________#
point.in.region<-function(point.long,point.lat,regionk){#
	in.region<-c()#
	for (i in 1:length(regionk@polygons)){#
		in.polygon<-c()#
		in.hole<-c()#
		for(j in 1:length(regionk@polygons[[i]]@Polygons)){#
			coords.ij<-regionk@polygons[[i]]@Polygons[[j]]@coords#
			in.polygon[j]<-point.in.polygon(point.long,point.lat,coords.ij[,1],coords.ij[,2])#
			if (regionk@polygons[[i]]@Polygons[[j]]@hole==TRUE){#
				in.hole[j]<-1#
			} else {#
				in.hole[j]<-0#
			}	#
		}#
		temp<-cbind(in.hole,in.polygon)#
		if (sum(c(temp[,2]-temp[,1]) %in% 1)>0 && sum(c(temp[,2]-temp[,1]) %in% 0)==0){#
			in.region[i]<-1#
		} else {#
			in.region[i]<-0#
		}	#
	}#
#
	if (sum(in.region)>0){ in.ecoregion<-1#
	} else { in.ecoregion<-0 }	#
	return(in.ecoregion)#
}#
#
# assign.point________________________________________________________#
assign.point<-function(point.long,point.lat,ecoregions){#
	region.list<-unique(ecoregions$NA_L1NAME)#
	region.list<-region.list[-1]#
	classify.pt<-matrix(NA,nr=length(region.list),nc=2)#
	for (i in 1:length(region.list)){#
		regionk<-ecoregions[ecoregions$NA_L1NAME==region.list[i],]#
		inYN<-point.in.region(point.long,point.lat,regionk)#
		classify.pt[i,]<-c(as.character(region.list[i]),inYN)#
	}#
	classify.pt<-as.data.frame(classify.pt)#
	if (sum(as.numeric(as.vector(classify.pt[,2])))==0){#
	# some sites fall beyond the EPA ecoregion shapefiles#
	# those sites are assigned to the nearest polygon in this if statement#
		min.dist3<-c()#
		for (i in 1:length(region.list)){#
			regionk<-ecoregions[ecoregions$NA_L1NAME==region.list[i],]#
			min.dist2<-c()#
			for (j in 1:length(regionk@polygons)){#
				min.dist<-c()#
				for (k in 1: length(regionk@polygons[[j]]@Polygons)){#
					coords.ij<-regionk@polygons[[j]]@Polygons[[k]]@coords#
					min.dist[k]<-min(distGeo(c(point.long,point.lat),coords.ij))#
				}#
				min.dist2[j]<-min(min.dist)	#
			}#
			min.dist3[i]<-min(min.dist2)#
		}	#
		out<-as.character(region.list[which.min(min.dist3)])#
	} else {#
		out<-as.character(classify.pt[which(classify.pt[,2]==1),1])#
	}#
	return(out)#
}#
#
# ANALYSES ########################################
# SORT SITES INTO ECOREGIONS___#
ecoregions<-spTransform(ecoregions,"+proj=longlat +datum=WGS84")#
#
site.coords<-extract.coords(pol_dlx)#
#
site.names<-c()#
for (i in 1:length(pol_dlx)){#
	site.names[i]<-pol_dlx[[i]]$dataset$site.data$site.name	#
}#
#
ecoregs<-c()#
for (k in 1:nrow(site.coords)){#
	# print(k)#
	ecoregs[k]<-assign.point(site.coords[k,2],site.coords[k,3],ecoregions)#
}#
# table(ecoregs)#
#
site.meta<-cbind(site.coords[,1],site.names,site.coords[,2:3],ecoregs,rep(NA,nrow(site.coords)))#
colnames(site.meta)<-c("dataset.id","site.name","long","lat","ecoregion","site.group")#
site.meta<-as.data.frame(site.meta)#
#
# classify EPA ecoregions into combined regions#
groupA<-c("ARCTIC CORDILLERA","TUNDRA","TAIGA","HUDSON PLAIN")#
groupB<-"NORTHERN FORESTS"#
groupC<-c("NORTHWESTERN FORESTED MOUNTAINS","MARINE WEST COAST FOREST")#
groupD<-"EASTERN TEMPERATE FORESTS"#
groupE<-"GREAT PLAINS"#
groupF<-c("MEDITERRANEAN CALIFORNIA","NORTH AMERICAN DESERTS","SOUTHERN SEMIARID HIGHLANDS","TEMPERATE SIERRAS")#
groupG<-c("TROPICAL DRY FORESTS","TROPICAL WET FORESTS")#
#
site.meta$site.group[which(site.meta$ecoregion %in% groupA)]<-"A" # populate site.group column in site.meta table#
site.meta$site.group[which(site.meta$ecoregion %in% groupB)]<-"B"#
site.meta$site.group[which(site.meta$ecoregion %in% groupC)]<-"C"#
site.meta$site.group[which(site.meta$ecoregion %in% groupD)]<-"D"#
site.meta$site.group[which(site.meta$ecoregion %in% groupE)]<-"E"#
site.meta$site.group[which(site.meta$ecoregion %in% groupF)]<-"F"#
site.meta$site.group[which(site.meta$ecoregion %in% groupG)]<-"G"#
#
Aobj<-site.meta[which(site.meta$site.group %in% "A"),1] # list of neotoma db id numbers for sits in each group#
Bobj<-site.meta[which(site.meta$site.group %in% "B"),1]#
Cobj<-site.meta[which(site.meta$site.group %in% "C"),1]#
Dobj<-site.meta[which(site.meta$site.group %in% "D"),1]#
Eobj<-site.meta[which(site.meta$site.group %in% "E"),1]#
Fobj<-site.meta[which(site.meta$site.group %in% "F"),1]#
Gobj<-site.meta[which(site.meta$site.group %in% "G"),1]#
#
sites.inbin<-list(Aobj,Bobj,Cobj,Dobj,Eobj,Fobj,Gobj)#
regions.lab<-c("A","B","C","D","E","F","G")#
names(sites.inbin)<-regions.lab#
#
# add to sites metadata table: number of samples, time span, number of terrestrial taxa
ecoregions<-readOGR("na_cec_eco_l1/NA_CEC_Eco_Level1.shp") # replace with appropriate file path
~/Desktop/Research_Git/fourpointtwo/2022-01/na_cec_eco_l1/NA_CEC_Eco_Level1.shp
ecoregions<-readOGR("~/Desktop/Research_Git/fourpointtwo/2022-01/na_cec_eco_l1/NA_CEC_Eco_Level1.shp") # replace with appropriate file path
# FUNCTIONS ######################
# LOAD FUNCTIONS__#
source('PaleoVegChange_functions.R', chdir = TRUE)#
#
# ADDITIONAL FUNCTIONS FOR DEFIINING REGIONS___#
extract.coords<-function(pol_dl_obj){#
	coords<-matrix(NA,nc=3,nr=length(pol_dl_obj))#
	for (i in 1:length(pol_dl_obj)){#
		coords[i,]<-c(pol_dl_obj[[i]]$dataset$dataset.meta$dataset.id,pol_dl_obj[[i]]$dataset$site.data$long,pol_dl_obj[[i]]$dataset$site.data$lat)	#
	}#
	return(coords)#
}#
#
# point.in.region________________________________#
point.in.region<-function(point.long,point.lat,regionk){#
	in.region<-c()#
	for (i in 1:length(regionk@polygons)){#
		in.polygon<-c()#
		in.hole<-c()#
		for(j in 1:length(regionk@polygons[[i]]@Polygons)){#
			coords.ij<-regionk@polygons[[i]]@Polygons[[j]]@coords#
			in.polygon[j]<-point.in.polygon(point.long,point.lat,coords.ij[,1],coords.ij[,2])#
			if (regionk@polygons[[i]]@Polygons[[j]]@hole==TRUE){#
				in.hole[j]<-1#
			} else {#
				in.hole[j]<-0#
			}	#
		}#
		temp<-cbind(in.hole,in.polygon)#
		if (sum(c(temp[,2]-temp[,1]) %in% 1)>0 && sum(c(temp[,2]-temp[,1]) %in% 0)==0){#
			in.region[i]<-1#
		} else {#
			in.region[i]<-0#
		}	#
	}#
#
	if (sum(in.region)>0){ in.ecoregion<-1#
	} else { in.ecoregion<-0 }	#
	return(in.ecoregion)#
}#
#
# assign.point________________________________________________________#
assign.point<-function(point.long,point.lat,ecoregions){#
	region.list<-unique(ecoregions$NA_L1NAME)#
	region.list<-region.list[-1]#
	classify.pt<-matrix(NA,nr=length(region.list),nc=2)#
	for (i in 1:length(region.list)){#
		regionk<-ecoregions[ecoregions$NA_L1NAME==region.list[i],]#
		inYN<-point.in.region(point.long,point.lat,regionk)#
		classify.pt[i,]<-c(as.character(region.list[i]),inYN)#
	}#
	classify.pt<-as.data.frame(classify.pt)#
	if (sum(as.numeric(as.vector(classify.pt[,2])))==0){#
	# some sites fall beyond the EPA ecoregion shapefiles#
	# those sites are assigned to the nearest polygon in this if statement#
		min.dist3<-c()#
		for (i in 1:length(region.list)){#
			regionk<-ecoregions[ecoregions$NA_L1NAME==region.list[i],]#
			min.dist2<-c()#
			for (j in 1:length(regionk@polygons)){#
				min.dist<-c()#
				for (k in 1: length(regionk@polygons[[j]]@Polygons)){#
					coords.ij<-regionk@polygons[[j]]@Polygons[[k]]@coords#
					min.dist[k]<-min(distGeo(c(point.long,point.lat),coords.ij))#
				}#
				min.dist2[j]<-min(min.dist)	#
			}#
			min.dist3[i]<-min(min.dist2)#
		}	#
		out<-as.character(region.list[which.min(min.dist3)])#
	} else {#
		out<-as.character(classify.pt[which(classify.pt[,2]==1),1])#
	}#
	return(out)#
}#
#
# ANALYSES ########################################
# SORT SITES INTO ECOREGIONS___#
ecoregions<-spTransform(ecoregions,"+proj=longlat +datum=WGS84")
site.coords<-extract.coords(pol_dlx)#
#
site.names<-c()#
for (i in 1:length(pol_dlx)){#
	site.names[i]<-pol_dlx[[i]]$dataset$site.data$site.name	#
}#
#
ecoregs<-c()#
for (k in 1:nrow(site.coords)){#
	# print(k)#
	ecoregs[k]<-assign.point(site.coords[k,2],site.coords[k,3],ecoregions)#
}#
# table(ecoregs)#
#
site.meta<-cbind(site.coords[,1],site.names,site.coords[,2:3],ecoregs,rep(NA,nrow(site.coords)))#
colnames(site.meta)<-c("dataset.id","site.name","long","lat","ecoregion","site.group")#
site.meta<-as.data.frame(site.meta)#
#
# classify EPA ecoregions into combined regions#
groupA<-c("ARCTIC CORDILLERA","TUNDRA","TAIGA","HUDSON PLAIN")#
groupB<-"NORTHERN FORESTS"#
groupC<-c("NORTHWESTERN FORESTED MOUNTAINS","MARINE WEST COAST FOREST")#
groupD<-"EASTERN TEMPERATE FORESTS"#
groupE<-"GREAT PLAINS"#
groupF<-c("MEDITERRANEAN CALIFORNIA","NORTH AMERICAN DESERTS","SOUTHERN SEMIARID HIGHLANDS","TEMPERATE SIERRAS")#
groupG<-c("TROPICAL DRY FORESTS","TROPICAL WET FORESTS")#
#
site.meta$site.group[which(site.meta$ecoregion %in% groupA)]<-"A" # populate site.group column in site.meta table#
site.meta$site.group[which(site.meta$ecoregion %in% groupB)]<-"B"#
site.meta$site.group[which(site.meta$ecoregion %in% groupC)]<-"C"#
site.meta$site.group[which(site.meta$ecoregion %in% groupD)]<-"D"#
site.meta$site.group[which(site.meta$ecoregion %in% groupE)]<-"E"#
site.meta$site.group[which(site.meta$ecoregion %in% groupF)]<-"F"#
site.meta$site.group[which(site.meta$ecoregion %in% groupG)]<-"G"#
#
Aobj<-site.meta[which(site.meta$site.group %in% "A"),1] # list of neotoma db id numbers for sits in each group#
Bobj<-site.meta[which(site.meta$site.group %in% "B"),1]#
Cobj<-site.meta[which(site.meta$site.group %in% "C"),1]#
Dobj<-site.meta[which(site.meta$site.group %in% "D"),1]#
Eobj<-site.meta[which(site.meta$site.group %in% "E"),1]#
Fobj<-site.meta[which(site.meta$site.group %in% "F"),1]#
Gobj<-site.meta[which(site.meta$site.group %in% "G"),1]#
#
sites.inbin<-list(Aobj,Bobj,Cobj,Dobj,Eobj,Fobj,Gobj)#
regions.lab<-c("A","B","C","D","E","F","G")#
names(sites.inbin)<-regions.lab
meta.out<-matrix(NA,nrow=nrow(site.meta),ncol=4)#
for (i in 1:nrow(site.meta)){#
	site.i<-pol_dlx[[site.meta$dataset.id[i]]]#
	n.samp<-nrow(site.i$sample.meta) # number of samples#
	# age.range<-round(range(site.i$sample.meta$age)) # time span#
	n.terrestrial<-ncol(clean_pollen(site.i,type="pct",eco.group=c("TRSH","UPHE"))) # number of terrestrial pollen types#
	pol_ds<-pol_dlx[[i]]#
	handlej<-pol_ds$dataset$dataset.meta$collection.handle # get site handle#
	handle.path<-paste(path,"/",handlej,sep="") #
	file.name<-dir(handle.path,pattern="ages.txt") # use handle to import bacon iterations#
	file.path<-paste(handle.path,"/",file.name,sep="")#
	am<-read.table(file.path,header=T)#
	age.range<-range(am$median)#
	meta.out[i,]<-c(n.samp,n.terrestrial,age.range)#
}
colnames(meta.out)<-c("N samples","N terrestrial pollen types","Age Younger","Age Older")
meta.out
meta.data.full<-cbind(site.meta[1:4],meta.out,site.meta[,5:6])
write.csv(meta.data.full,"~/Desktop/Research_Git/fourpointtwo/2022-01/results/site-metadata.csv")
